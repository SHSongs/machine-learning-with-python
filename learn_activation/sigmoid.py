import numpy as np
import matplotlib.pylab as plt

# 출력값이 0과 1 사이, 매끄러운 곡선으로 역전파 시, 기울기 폭주 발생 안함
# 분류는 0과 1 출력값이 어디에 가까운지에 따라 정해짐

# 입력값이 커도 0과 1 사이이기에 역전파시 기울기 0에 수렴하는 기울기 소실 발생
# 중앙값이 0.5이기에 출력이 입력보다 커짐
# 이를 편향 이동(bias gradient)라 함, 레이어 통과시마다 분산이 커져, 활성화 함수의 출력이 최대 최소인 0과 1에 수렴 ?? 왜 최소에도 수렴하는지 test 필요
# 시그모이드 출력이 0과 1이면 도함수는 0
# 이로 인해 기울기가 0 이고 역전파시 전해지는게 없게 됨
# 출력이 양수이기에, 기울기는 모두 양수나 음수, 이는 기울기 업데이트가 지그재그로 변동해 학습 효율 감소 ( 왜 기울기가 양수나 음수인지 확인 필요 )

def sigmoid(x):
    return 1 / (1 + np.exp(-x))


x = np.arange(-20.0, 20.0, 0.1)
y = sigmoid(x)
plt.plot(x, y)
plt.ylim(-0.1, 1.1)
plt.show()
